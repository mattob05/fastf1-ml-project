{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8168dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef57be5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17127, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(dir, '..'))\n",
    "data_root = os.path.join(project_root, 'data')\n",
    "\n",
    "tel = pd.read_csv(filepath_or_buffer=os.path.join(data_root, 'f1_telemetry_agg.csv'))\n",
    "df_train = pd.read_csv(filepath_or_buffer=os.path.join(data_root, 'f1_train.csv'))\n",
    "df_test = pd.read_csv(filepath_or_buffer=os.path.join(data_root, 'f1_test.csv'))\n",
    "\n",
    "df_train = df_train.merge(tel, how='left', on=['RoundNumber', 'LapNumber', 'DriverNumber'])\n",
    "df_test = df_test.merge(tel, how='left', on=['RoundNumber', 'LapNumber', 'DriverNumber'])\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fb6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_imputed = df_train.copy()\n",
    "df_train = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e529ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_cols = [\n",
    "    'RoundNumber', 'LapNumber', 'DriverNumber',  \n",
    "    'TyreLife', 'TrackTemp', 'FuelLevel', 'SpeedST',                \n",
    "    'AvgCorneringSpeed', 'AvgRPM', 'AvgThrottle', 'BrakePct' , 'GearShifts', 'MaxSpeed'\n",
    "]\n",
    "\n",
    "imputer = IterativeImputer(\n",
    "    estimator=BayesianRidge(),\n",
    "    max_iter=15, \n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "data_to_impute = df_train_imputed[impute_cols].copy()\n",
    "\n",
    "imputed_matrix = imputer.fit_transform(data_to_impute)\n",
    "\n",
    "df_train_imputed[impute_cols] = imputed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0babc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(df_train, df_test, col_to_drop, model):\n",
    "    X_train = df_train.drop(columns=col_to_drop)\n",
    "    X_test = df_test.drop(columns=col_to_drop)\n",
    "    y_train = df_train['Target']\n",
    "    y_test = df_test['Target']\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'MAE on target: {mean_absolute_error(y_test, y_pred)}')\n",
    "    y_pred = y_pred * df_test['QualiBest']\n",
    "    mae = mean_absolute_error(df_test['LapTime'], y_pred)\n",
    "    mape = mean_absolute_percentage_error(df_test['LapTime'], y_pred)\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MAPE: {mape}')\n",
    "    return df_test['LapTime'], y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "266e6823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DriverNumber         0\n",
       "LapTime              0\n",
       "LapNumber            0\n",
       "SpeedST              0\n",
       "TyreLife             0\n",
       "TrackTemp            0\n",
       "Rainfall             0\n",
       "Position             0\n",
       "RoundNumber          0\n",
       "FuelLevel            0\n",
       "QualiBest            0\n",
       "Target               0\n",
       "DriverPower          0\n",
       "TeamPace             0\n",
       "C_INTERMEDIATE       0\n",
       "Length               0\n",
       "Traction             0\n",
       "Abrasion             0\n",
       "TrackEvolution       0\n",
       "TyreStress           0\n",
       "Lateral              0\n",
       "Downforce            0\n",
       "CompoundRating       0\n",
       "GapAhead             0\n",
       "GapBehind            0\n",
       "AvgCorneringSpeed    0\n",
       "MaxSpeed             0\n",
       "AvgRPM               0\n",
       "GearShifts           0\n",
       "AvgThrottle          0\n",
       "BrakePct             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_imputed.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7770664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17104, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f0f7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model with imputed data ---\n",
      "MAE on target: 0.010828160546820882\n",
      "MAE: 0.8085907032209383\n",
      "MAPE: 0.010014105207687514\n",
      "--- Model with deleted ---\n",
      "MAE on target: 0.010459369821280547\n",
      "MAE: 0.7822369672753097\n",
      "MAPE: 0.009662962975866113\n"
     ]
    }
   ],
   "source": [
    "col_to_drop = ['LapTime', 'DriverNumber', 'RoundNumber', 'LapNumber', 'Target', 'QualiBest']\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    min_samples_leaf=25,\n",
    "    max_depth=15,\n",
    "    n_jobs=-1,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    "    )\n",
    "print('--- Model with imputed data ---')\n",
    "_, _ = eval_model(df_train_imputed, df_test, col_to_drop, model)\n",
    "print('--- Model with deleted ---')\n",
    "y_test, y_pred = eval_model(df_train, df_test, col_to_drop, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f2db5e",
   "metadata": {},
   "source": [
    "As we can see, the imputed data only introduces noise, so we will delete records without telemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ef1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([df_train_imputed, df_test], axis=0)\n",
    "full_df.to_csv(os.path.join(data_root, 'full_f1_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f34bb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
